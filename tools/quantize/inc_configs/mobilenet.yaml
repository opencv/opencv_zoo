#
# Copyright (c) 2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

version: 1.0

model:                                               # mandatory. used to specify model specific information.
  name: mobilenetv2
  framework: onnxrt_qlinearops                       # mandatory. supported values are tensorflow, pytorch, pytorch_ipex, onnxrt_integer, onnxrt_qlinear or mxnet; allow new framework backend extension.

quantization:                                        # optional. tuning constraints on model-wise for advance user to reduce tuning space.
  approach: post_training_static_quant               # optional. default value is post_training_static_quant.                          
  calibration:
    dataloader:
      batch_size: 1
      dataset:
        ImagenetRaw:
          data_path: /path/to/imagenet/val
          image_list: /path/to/imagenet/val.txt      # download from http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz
      transform:
        Rescale: {}
        Resize:
          size: 256
        CenterCrop:
          size: 224
        Normalize:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
        Transpose:
          perm: [2, 0, 1]
        Cast:
          dtype: float32
evaluation:                                          # optional. required if user doesn't provide eval_func in lpot.Quantization.
  accuracy:                                          # optional. required if user doesn't provide eval_func in lpot.Quantization.
    metric:
      topk: 1                                        # built-in metrics are topk, map, f1, allow user to register new metric.
    dataloader:
      batch_size: 1
      dataset:
        ImagenetRaw:
          data_path: /path/to/imagenet/val
          image_list: /path/to/imagenet/val.txt      # download from http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz
       transform:
        Rescale: {}
        Resize:
          size: 256
        CenterCrop:
          size: 224
        Normalize:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
        Transpose:
          perm: [2, 0, 1]
        Cast:
          dtype: float32
  performance:                                       # optional. used to benchmark performance of passing model.
    warmup: 10
    iteration: 1000
    configs:
      cores_per_instance: 4
      num_of_instance: 1
    dataloader:
      batch_size: 1 
      dataset:
        ImagenetRaw:
          data_path: /path/to/imagenet/val
          image_list: /path/to/imagenet/val.txt      # download from http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz
      transform:
        Rescale: {}
        Resize:
          size: 256
        CenterCrop:
          size: 224
        Normalize:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
        Transpose:
          perm: [2, 0, 1]
        Cast:
          dtype: float32

tuning:
  accuracy_criterion:
    relative:  0.02                                  # optional. default value is relative, other value is absolute. this example allows relative accuracy loss: 1%.
  exit_policy:
    timeout: 0                                       # optional. tuning timeout (seconds). default value is 0 which means early stop. combine with max_trials field to decide when to exit.
  random_seed: 9527                                  # optional. random seed for deterministic tuning.
